{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scipy.special as sps\n",
    "import scipy.stats as scstats\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import transforms\n",
    "import daft\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../neuroprob\")\n",
    "sys.path.append(\"../scripts/\") # access to scripts\n",
    "\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./output'):\n",
    "    os.makedirs('./output')\n",
    "    \n",
    "\n",
    "from neuroprob import utils\n",
    "\n",
    "import model_utils\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "plt.style.use(['paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(pgm):\n",
    "    \"\"\"\n",
    "    Wrapper for rendering PGM via daft\n",
    "    \"\"\"\n",
    "    for plate in pgm._plates:\n",
    "        plate.render(pgm._ctx)\n",
    "\n",
    "    for edge in pgm._edges:\n",
    "        edge.render(pgm._ctx)\n",
    "\n",
    "    for name in pgm._nodes:\n",
    "        pgm._nodes[name].render(pgm._ctx)\n",
    "\n",
    "\n",
    "\n",
    "def init_figax(pgm, fig, ax):\n",
    "    \"\"\"\n",
    "    Wrapper for initializing PGM via daft\n",
    "    \"\"\"\n",
    "    pgm._ctx._figure = fig\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Set the bounds.\n",
    "    l0 = pgm._ctx.convert(*pgm._ctx.origin)\n",
    "    l1 = pgm._ctx.convert(*(pgm._ctx.origin + pgm._ctx.shape))\n",
    "    ax.set_xlim(l0[0], l1[0])\n",
    "    ax.set_ylim(l0[1], l1[1])\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    pgm._ctx._ax = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic process over point process conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(10, 100)*5.+10.0\n",
    "dt = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tl = 3000\n",
    "sample_bin = 0.001\n",
    "\n",
    "\n",
    "l = sample_bin*np.array([30.0])[None, :]\n",
    "dn = l.shape[1]\n",
    "v = np.ones(dn)\n",
    "\n",
    "\n",
    "\n",
    "# generate GP trajectories\n",
    "kernel_tuples = [('variance', v), \n",
    "                 ('RBF', 'euclid', l)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    kernel, _, _ = GP.kernels.create_kernel(kernel_tuples, 'softplus', torch.double)\n",
    "\n",
    "    inp = torch.arange(Tl)[None, None, :, None]*sample_bin\n",
    "    K = kernel(inp, inp)[0, ...]\n",
    "    K.view(dn, -1)[:, ::Tl+1] += 1e-6\n",
    "\n",
    "\n",
    "L = torch.cholesky(K)\n",
    "mc = 10\n",
    "xi = np.random.randn(mc, dn, Tl)\n",
    "x = (L[None, ...] * xi[..., None, :]).sum(-1)\n",
    "\n",
    "\n",
    "\n",
    "# linear Poisson model\n",
    "neurons = 100\n",
    "w_len = dn\n",
    "GPFA = mdl.parametrics.GLM(w_len, neurons, w_len, 'exp', bias=True)\n",
    "\n",
    "w = np.random.randn(neurons, w_len)\n",
    "bias = np.random.randn(neurons)\n",
    "GPFA.set_params(w, bias)\n",
    "\n",
    "\n",
    "likelihood = mdl.likelihoods.Poisson(sample_bin, neurons, 'exp')\n",
    "#likelihood.set_Y(rc_t, batch_size=5000, filter_len=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.numpy()[1, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.exp(x)\n",
    "p = x.numpy()[:, 0, :]*np.exp(-np.cumsum(x.numpy()[:, 0, :], axis=1)*dt) # natural time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = np.arange(Tl)*dt\n",
    "tau_0 = 0.001\n",
    "t = tau_0*(np.exp(tau) - 1)\n",
    "dtau_dt = 1/(t+tau_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tau, p.mean(0).T)\n",
    "plt.plot(tau[:, None].repeat(p.shape[0], axis=1), p.T, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, p.mean(0).T*dtau_dt)\n",
    "plt.plot(t[:, None].repeat(p.shape[0], axis=1), p.T*dtau_dt[:, None], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p*dt).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 1\n",
    "hist_couple = None\n",
    "shape_t = 5.0*np.ones(neurons)\n",
    "likelihood = mdl.likelihoods.Gamma(sample_bin, neurons, rate_model.inv_link, shape_t)\n",
    "#sigma_t = 0.5*np.ones(neurons)\n",
    "#likelihood = mdl.likelihoods.logNormal(sample_bin, neurons, inv_link, sigma_t)\n",
    "\n",
    "#mu_t = 5.0*np.ones(neurons)\n",
    "#likelihood = mdl.likelihoods.invGaussian(neurons, inv_link, mu_t)\n",
    "\n",
    "#hist_len = 99 # 100 steps of spiketrain, no instantaneous element\n",
    "#hist_couple = mdl.filters.raised_cosine_bumps(a=1., c=1., phi=phi_h, w=w_h, timesteps=hist_len)\n",
    "#likelihood = mdl.likelihoods.Bernoulli(neurons, inv_link)\n",
    "\n",
    "#input_group = mdl.inference.input_group(3, [(None, None, None, 1)]*3)\n",
    "#input_group.set_XZ(covariates, track_samples, batch_size=track_samples, trials=trials)\n",
    "\n",
    "#glm = mdl.inference.VI_optimized(input_group, gauss_rate, likelihood)\n",
    "#glm.to(dev)\n",
    "    \n",
    "\n",
    "bb_isi = np.linspace(0.001, 5.0, 100) # ISI evaluate\n",
    "\n",
    "#gt_field.append(compute_rate(model.rate_model[0], [0])[0])\n",
    "ISI = [torch.tensor(bb_isi[:, None], device='cpu')]#dev)]\n",
    "scale = likelihood.shape.data\n",
    "#scale = torch.exp(-model.likelihood.sigma.data**2/2.)\n",
    "#scale = 1./model.likelihood.mu\n",
    "likelihood.trials = 1\n",
    "p = likelihood.nll(torch.log(scale)*torch.ones((len(bb_isi), 1), device='cpu'), [[ISI[0]*scale]], [0])#.data[:, 0].cpu().numpy()\n",
    "a = np.exp(-p)\n",
    "\n",
    "b = likelihood.ISI_dist([0]).prob_dens(bb_isi)\n",
    "\n",
    "plt.plot(bb_isi, a)\n",
    "plt.plot(bb_isi, b, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5)) # plot fits\n",
    "fig.text(-0.21, 1.16, 'A', transform=ax.transAxes, size=15)\n",
    "\n",
    "time_bins = I_ext[0].shape[0]\n",
    "tt = np.arange(time_bins)*dt\n",
    "\n",
    "\n",
    "\n",
    "widths = [1]\n",
    "heights = [1, 1, 1, 2]\n",
    "spec = fig.add_gridspec(ncols=1, nrows=4, width_ratios=widths, height_ratios=heights, \n",
    "                        left=0., right=0.7, bottom=0., top=1.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
