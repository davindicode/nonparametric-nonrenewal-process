{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scipy.special as sps\n",
    "import scipy.stats as scstats\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from matplotlib import transforms\n",
    "import daft\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../neuroprob\")\n",
    "sys.path.append(\"../scripts/\") # access to scripts\n",
    "\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./output'):\n",
    "    os.makedirs('./output')\n",
    "    \n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "plt.style.use(['../paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(pgm):\n",
    "    \"\"\"\n",
    "    Wrapper for rendering PGM via daft\n",
    "    \"\"\"\n",
    "    for plate in pgm._plates:\n",
    "        plate.render(pgm._ctx)\n",
    "\n",
    "    for edge in pgm._edges:\n",
    "        edge.render(pgm._ctx)\n",
    "\n",
    "    for name in pgm._nodes:\n",
    "        pgm._nodes[name].render(pgm._ctx)\n",
    "\n",
    "\n",
    "\n",
    "def init_figax(pgm, fig, ax):\n",
    "    \"\"\"\n",
    "    Wrapper for initializing PGM via daft\n",
    "    \"\"\"\n",
    "    pgm._ctx._figure = fig\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Set the bounds.\n",
    "    l0 = pgm._ctx.convert(*pgm._ctx.origin)\n",
    "    l1 = pgm._ctx.convert(*(pgm._ctx.origin + pgm._ctx.shape))\n",
    "    ax.set_xlim(l0[0], l1[0])\n",
    "    ax.set_ylim(l0[1], l1[1])\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    pgm._ctx._ax = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic process over point process conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(10, 100)*5.+10.0\n",
    "dt = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-798cad4a0133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_tuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softplus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample_bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GP' is not defined"
     ]
    }
   ],
   "source": [
    "Tl = 3000\n",
    "sample_bin = 0.001\n",
    "\n",
    "\n",
    "l = sample_bin*np.array([30.0])[None, :]\n",
    "dn = l.shape[1]\n",
    "v = np.ones(dn)\n",
    "\n",
    "\n",
    "\n",
    "# generate GP trajectories\n",
    "kernel_tuples = [('variance', v), \n",
    "                 ('RBF', 'euclid', l)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    kernel, _, _ = GP.kernels.create_kernel(kernel_tuples, 'softplus', torch.double)\n",
    "\n",
    "    inp = torch.arange(Tl)[None, None, :, None]*sample_bin\n",
    "    K = kernel(inp, inp)[0, ...]\n",
    "    K.view(dn, -1)[:, ::Tl+1] += 1e-6\n",
    "\n",
    "\n",
    "L = torch.cholesky(K)\n",
    "mc = 10\n",
    "xi = np.random.randn(mc, dn, Tl)\n",
    "x = (L[None, ...] * xi[..., None, :]).sum(-1)\n",
    "\n",
    "\n",
    "\n",
    "# linear Poisson model\n",
    "neurons = 100\n",
    "w_len = dn\n",
    "GPFA = mdl.parametrics.GLM(w_len, neurons, w_len, 'exp', bias=True)\n",
    "\n",
    "w = np.random.randn(neurons, w_len)\n",
    "bias = np.random.randn(neurons)\n",
    "GPFA.set_params(w, bias)\n",
    "\n",
    "\n",
    "likelihood = mdl.likelihoods.Poisson(sample_bin, neurons, 'exp')\n",
    "#likelihood.set_Y(rc_t, batch_size=5000, filter_len=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x.numpy()[1, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.exp(x)\n",
    "p = x.numpy()[:, 0, :]*np.exp(-np.cumsum(x.numpy()[:, 0, :], axis=1)*dt) # natural time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time transform\n",
    "t = np.arange(1000)\n",
    "t0 = 100\n",
    "tau = (1 - np.exp(-t / t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f12597a69e8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tau, p.mean(0).T)\n",
    "plt.plot(tau[:, None].repeat(p.shape[0], axis=1), p.T, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, p.mean(0).T*dtau_dt)\n",
    "plt.plot(t[:, None].repeat(p.shape[0], axis=1), p.T*dtau_dt[:, None], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p*dt).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 1\n",
    "hist_couple = None\n",
    "shape_t = 5.0*np.ones(neurons)\n",
    "likelihood = mdl.likelihoods.Gamma(sample_bin, neurons, rate_model.inv_link, shape_t)\n",
    "#sigma_t = 0.5*np.ones(neurons)\n",
    "#likelihood = mdl.likelihoods.logNormal(sample_bin, neurons, inv_link, sigma_t)\n",
    "\n",
    "#mu_t = 5.0*np.ones(neurons)\n",
    "#likelihood = mdl.likelihoods.invGaussian(neurons, inv_link, mu_t)\n",
    "\n",
    "#hist_len = 99 # 100 steps of spiketrain, no instantaneous element\n",
    "#hist_couple = mdl.filters.raised_cosine_bumps(a=1., c=1., phi=phi_h, w=w_h, timesteps=hist_len)\n",
    "#likelihood = mdl.likelihoods.Bernoulli(neurons, inv_link)\n",
    "\n",
    "#input_group = mdl.inference.input_group(3, [(None, None, None, 1)]*3)\n",
    "#input_group.set_XZ(covariates, track_samples, batch_size=track_samples, trials=trials)\n",
    "\n",
    "#glm = mdl.inference.VI_optimized(input_group, gauss_rate, likelihood)\n",
    "#glm.to(dev)\n",
    "    \n",
    "\n",
    "bb_isi = np.linspace(0.001, 5.0, 100) # ISI evaluate\n",
    "\n",
    "#gt_field.append(compute_rate(model.rate_model[0], [0])[0])\n",
    "ISI = [torch.tensor(bb_isi[:, None], device='cpu')]#dev)]\n",
    "scale = likelihood.shape.data\n",
    "#scale = torch.exp(-model.likelihood.sigma.data**2/2.)\n",
    "#scale = 1./model.likelihood.mu\n",
    "likelihood.trials = 1\n",
    "p = likelihood.nll(torch.log(scale)*torch.ones((len(bb_isi), 1), device='cpu'), [[ISI[0]*scale]], [0])#.data[:, 0].cpu().numpy()\n",
    "a = np.exp(-p)\n",
    "\n",
    "b = likelihood.ISI_dist([0]).prob_dens(bb_isi)\n",
    "\n",
    "plt.plot(bb_isi, a)\n",
    "plt.plot(bb_isi, b, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### monotonic RQ splines ###\n",
    "def searchsorted(bin_locations, inputs, eps=1e-6):\n",
    "    bin_locations[..., -1] += eps\n",
    "    return torch.sum(inputs[..., None] >= bin_locations, dim=-1) - 1\n",
    "\n",
    "\n",
    "def RQS(\n",
    "    inputs,\n",
    "    unnormalized_widths,\n",
    "    unnormalized_heights,\n",
    "    unnormalized_derivatives,\n",
    "    inverse=False,\n",
    "    left=0.0,\n",
    "    right=1.0,\n",
    "    bottom=0.0,\n",
    "    top=1.0,\n",
    "    min_bin_width=1e-3,\n",
    "    min_bin_height=1e-3,\n",
    "    min_derivative=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    last dimension of params is number of bins\n",
    "    first dimensions are (batch,) or (batch, dims)\n",
    "\n",
    "    Based on implementation in https://github.com/bayesiains/nsf\n",
    "    \"\"\"\n",
    "    if torch.min(inputs) < left or torch.max(inputs) > right:\n",
    "        raise ValueError(\"Input outside domain\")\n",
    "\n",
    "    num_bins = unnormalized_widths.shape[-1]\n",
    "\n",
    "    if min_bin_width * num_bins > 1.0:\n",
    "        raise ValueError(\"Minimal bin width too large for the number of bins\")\n",
    "    if min_bin_height * num_bins > 1.0:\n",
    "        raise ValueError(\"Minimal bin height too large for the number of bins\")\n",
    "\n",
    "    widths = nn.functional.softmax(unnormalized_widths, dim=-1)\n",
    "    widths = min_bin_width + (1 - min_bin_width * num_bins) * widths\n",
    "    cumwidths = torch.cumsum(widths, dim=-1)\n",
    "    cumwidths = nn.functional.pad(cumwidths, pad=(1, 0), mode=\"constant\", value=0.0)\n",
    "    cumwidths = (right - left) * cumwidths + left\n",
    "    cumwidths[..., 0] = left\n",
    "    cumwidths[..., -1] = right\n",
    "    widths = cumwidths[..., 1:] - cumwidths[..., :-1]\n",
    "\n",
    "    derivatives = min_derivative + nn.functional.softplus(unnormalized_derivatives)\n",
    "\n",
    "    heights = nn.functional.softmax(unnormalized_heights, dim=-1)\n",
    "    heights = min_bin_height + (1 - min_bin_height * num_bins) * heights\n",
    "    cumheights = torch.cumsum(heights, dim=-1)\n",
    "    cumheights = nn.functional.pad(cumheights, pad=(1, 0), mode=\"constant\", value=0.0)\n",
    "    cumheights = (top - bottom) * cumheights + bottom\n",
    "    cumheights[..., 0] = bottom\n",
    "    cumheights[..., -1] = top\n",
    "    heights = cumheights[..., 1:] - cumheights[..., :-1]\n",
    "\n",
    "    if inverse:\n",
    "        bin_idx = searchsorted(cumheights, inputs)[..., None]\n",
    "    else:\n",
    "        bin_idx = searchsorted(cumwidths, inputs)[..., None]\n",
    "\n",
    "    input_cumwidths = cumwidths.gather(-1, bin_idx)[..., 0]\n",
    "    input_bin_widths = widths.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_cumheights = cumheights.gather(-1, bin_idx)[..., 0]\n",
    "    delta = heights / widths\n",
    "    input_delta = delta.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_derivatives = derivatives.gather(-1, bin_idx)[..., 0]\n",
    "    input_derivatives_plus_one = derivatives[..., 1:].gather(-1, bin_idx)\n",
    "    input_derivatives_plus_one = input_derivatives_plus_one[..., 0]\n",
    "\n",
    "    input_heights = heights.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    if inverse:\n",
    "        a = (inputs - input_cumheights) * (\n",
    "            input_derivatives + input_derivatives_plus_one - 2 * input_delta\n",
    "        ) + input_heights * (input_delta - input_derivatives)\n",
    "        b = input_heights * input_derivatives - (inputs - input_cumheights) * (\n",
    "            input_derivatives + input_derivatives_plus_one - 2 * input_delta\n",
    "        )\n",
    "        c = -input_delta * (inputs - input_cumheights)\n",
    "\n",
    "        discriminant = b.pow(2) - 4 * a * c\n",
    "        assert (discriminant >= 0).all()\n",
    "\n",
    "        root = (2 * c) / (-b - torch.sqrt(discriminant))\n",
    "        outputs = root * input_bin_widths + input_cumwidths\n",
    "\n",
    "        theta_one_minus_theta = root * (1 - root)\n",
    "        denominator = input_delta + (\n",
    "            (input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "            * theta_one_minus_theta\n",
    "        )\n",
    "        derivative_numerator = input_delta.pow(2) * (\n",
    "            input_derivatives_plus_one * root.pow(2)\n",
    "            + 2 * input_delta * theta_one_minus_theta\n",
    "            + input_derivatives * (1 - root).pow(2)\n",
    "        )\n",
    "        logdetjac = torch.log(derivative_numerator) - 2 * torch.log(denominator)\n",
    "        return outputs, -logdetjac\n",
    "\n",
    "    else:\n",
    "        theta = (inputs - input_cumwidths) / input_bin_widths\n",
    "        theta_one_minus_theta = theta * (1 - theta)\n",
    "\n",
    "        numerator = input_heights * (\n",
    "            input_delta * theta.pow(2) + input_derivatives * theta_one_minus_theta\n",
    "        )\n",
    "        denominator = input_delta + (\n",
    "            (input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "            * theta_one_minus_theta\n",
    "        )\n",
    "        outputs = input_cumheights + numerator / denominator\n",
    "\n",
    "        derivative_numerator = input_delta.pow(2) * (\n",
    "            input_derivatives_plus_one * theta.pow(2)\n",
    "            + 2 * input_delta * theta_one_minus_theta\n",
    "            + input_derivatives * (1 - theta).pow(2)\n",
    "        )\n",
    "        logdetjac = torch.log(derivative_numerator) - 2 * torch.log(denominator)\n",
    "        return outputs, logdetjac\n",
    "\n",
    "\n",
    "def unconstrained_RQS(\n",
    "    inputs,\n",
    "    unnormalized_widths,\n",
    "    unnormalized_heights,\n",
    "    unnormalized_derivatives,\n",
    "    inverse=False,\n",
    "    tail_bound=1.0,\n",
    "    min_bin_width=1e-3,\n",
    "    min_bin_height=1e-3,\n",
    "    min_derivative=1e-3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Based on implementation in https://github.com/bayesiains/nsf\n",
    "    \"\"\"\n",
    "    outputs = torch.zeros_like(inputs)\n",
    "    logdetjac = torch.zeros_like(inputs)\n",
    "\n",
    "    unnormalized_derivatives = nn.functional.pad(unnormalized_derivatives, pad=(1, 1))\n",
    "    constant = math.log(math.exp(1 - min_derivative) - 1)\n",
    "    unnormalized_derivatives[..., 0] = constant\n",
    "    unnormalized_derivatives[..., -1] = constant\n",
    "\n",
    "    inside_intvl_mask = (inputs >= -tail_bound) & (inputs <= tail_bound)\n",
    "    outside_interval_mask = ~inside_intvl_mask\n",
    "\n",
    "    if outside_interval_mask.sum() > 0:\n",
    "        outputs[outside_interval_mask] = inputs[outside_interval_mask]\n",
    "        logdetjac[outside_interval_mask] = 0\n",
    "\n",
    "    if inside_intvl_mask.sum() > 0:\n",
    "        outputs[inside_intvl_mask], logdetjac[inside_intvl_mask] = RQS(\n",
    "            inputs=inputs[inside_intvl_mask],\n",
    "            unnormalized_widths=unnormalized_widths[inside_intvl_mask, :],\n",
    "            unnormalized_heights=unnormalized_heights[inside_intvl_mask, :],\n",
    "            unnormalized_derivatives=unnormalized_derivatives[inside_intvl_mask, :],\n",
    "            inverse=inverse,\n",
    "            left=-tail_bound,\n",
    "            right=tail_bound,\n",
    "            bottom=-tail_bound,\n",
    "            top=tail_bound,\n",
    "            min_bin_width=min_bin_width,\n",
    "            min_bin_height=min_bin_height,\n",
    "            min_derivative=min_derivative,\n",
    "        )\n",
    "\n",
    "    return outputs, logdetjac\n",
    "\n",
    "\n",
    "class NRQS(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural rational quadratic spline flow, coupling layer\n",
    "\n",
    "    [Durkan et al. 2019]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask1, f1, f2, K, B):\n",
    "        \"\"\"\n",
    "        f1 and f2 take in full input x and map out flattened (3 * K - 1) * dims\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dim1 = mask1.sum()\n",
    "        self.dim2 = np.prod(mask1.shape) - self.dim1\n",
    "        self.K = K\n",
    "        self.B = B\n",
    "\n",
    "        self.register_buffer(\"mask1\", mask1.type(torch.bool))  # add batch dimension\n",
    "        self.register_buffer(\"mask2\", ~mask1.type(torch.bool))\n",
    "        self.f1 = f1  # output (3 * K - 1) * dim2\n",
    "        self.f2 = f2\n",
    "\n",
    "    def _compute_RQS(self, x, W, H, D, inverse):\n",
    "        W = 2 * self.B * torch.softmax(W, dim=2)\n",
    "        H = 2 * self.B * torch.softmax(H, dim=2)\n",
    "        D = nn.functional.softplus(D)\n",
    "        x, ld = unconstrained_RQS(x, W, H, D, inverse, tail_bound=self.B)\n",
    "        return x, ld\n",
    "\n",
    "    def forward(self, x, reverse=False, log_px=0):\n",
    "        \"\"\"\n",
    "        :param torch.tensor x: input of shape (batch, dims)\n",
    "        \"\"\"\n",
    "        x1, x2 = x[:, self.mask1], x[:, self.mask2]\n",
    "        x = torch.clone(x)  # copy to avoid overwriting input\n",
    "\n",
    "        if reverse:\n",
    "            x2_ = x * self.mask2\n",
    "            out = self.f2(x2_).reshape(-1, self.dim1, 3 * self.K - 1)\n",
    "            W, H, D = torch.split(out, self.K, dim=2)\n",
    "            x1, ld = self._compute_RQS(x1, W, H, D, inverse=True)\n",
    "            x[:, self.mask1] = x1  # update x1 part\n",
    "            log_px = log_px + torch.sum(ld, dim=1)\n",
    "\n",
    "            x1_ = x * self.mask1\n",
    "            out = self.f1(x1_).reshape(-1, self.dim2, 3 * self.K - 1)\n",
    "            W, H, D = torch.split(out, self.K, dim=2)\n",
    "            x2, ld = self._compute_RQS(x2, W, H, D, inverse=True)\n",
    "            x[:, self.mask2] = x2  # update x2 part\n",
    "            log_px = log_px + torch.sum(ld, dim=1)\n",
    "\n",
    "        else:\n",
    "            x1_ = x * self.mask1\n",
    "            out = self.f1(x1_).reshape(-1, self.dim2, 3 * self.K - 1)\n",
    "            W, H, D = torch.split(out, self.K, dim=2)\n",
    "            x2, ld = self._compute_RQS(x2, W, H, D, inverse=False)\n",
    "            x[:, self.mask2] = x2  # update x2 part\n",
    "            log_px = log_px + torch.sum(ld, dim=1)\n",
    "\n",
    "            x2_ = x * self.mask2\n",
    "            out = self.f2(x2_).reshape(-1, self.dim1, 3 * self.K - 1)\n",
    "            W, H, D = torch.split(out, self.K, dim=2)\n",
    "            x1, ld = self._compute_RQS(x1, W, H, D, inverse=False)\n",
    "            x[:, self.mask1] = x1  # update x1 part\n",
    "            log_px = log_px + torch.sum(ld, dim=1)\n",
    "\n",
    "        return x, log_px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5)) # plot fits\n",
    "fig.text(-0.21, 1.16, 'A', transform=ax.transAxes, size=15)\n",
    "\n",
    "time_bins = I_ext[0].shape[0]\n",
    "tt = np.arange(time_bins)*dt\n",
    "\n",
    "\n",
    "\n",
    "widths = [1]\n",
    "heights = [1, 1, 1, 2]\n",
    "spec = fig.add_gridspec(ncols=1, nrows=4, width_ratios=widths, height_ratios=heights, \n",
    "                        left=0., right=0.7, bottom=0., top=1.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
