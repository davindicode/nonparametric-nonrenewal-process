{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.6.0+cu101\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from neuroprob import stats, tools, neural_utils, animal\n",
    "import neuroprob.models as mdl\n",
    "\n",
    "dev = tools.PyTorch()\n",
    "\n",
    "\n",
    "plt.style.use(['paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_cov = hd_t, w_t, s_t, x_t, y_t\n",
    "\n",
    "# binning\n",
    "def binning(bin_size, spktrain):\n",
    "    tbin, resamples, rc_t, (rhd_t, rx_t, ry_t) = neural_utils.BinTrain(bin_size, sample_bin, spktrain, \n",
    "                                                        spktrain.shape[1], (np.unwrap(hd_t), x_t, y_t), \n",
    "                                                        average_behav=True, binned=True)\n",
    "\n",
    "\n",
    "    rw_t = (rhd_t[1:]-rhd_t[:-1])/tbin\n",
    "    rw_t = np.concatenate((rw_t, rw_t[-1:]))\n",
    "\n",
    "    rvx_t = (rx_t[1:]-rx_t[:-1])/tbin\n",
    "    rvy_t = (ry_t[1:]-ry_t[:-1])/tbin\n",
    "    rs_t = np.sqrt(rvx_t**2 + rvy_t**2)\n",
    "    rs_t = np.concatenate((rs_t, rs_t[-1:]))\n",
    "    rtime_t = np.arange(resamples)*tbin\n",
    "\n",
    "    units_used = rc_t.shape[0]\n",
    "    rcov = (tools.WrapPi(rhd_t, True), rw_t, rs_t, rx_t, ry_t, rtime_t)\n",
    "    return rcov, units_used, tbin, resamples, rc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_params(units, tbin, behav_tuple, num_induc):\n",
    "    \"\"\"\n",
    "    Setup GP parameters with input (x, y, speed, theta, hd)\n",
    "    \"\"\"\n",
    "    ind_list = [np.linspace(left_x, right_x, num_induc), \\\n",
    "                bottom_y + arena_height*np.random.rand(num_induc), \\\n",
    "                np.random.rand(num_induc)*100., \\\n",
    "                np.random.rand(num_induc)*2*np.pi, \\\n",
    "                np.random.rand(num_induc)*2*np.pi]\n",
    "\n",
    "    l = 10.*np.ones(units)\n",
    "    l_s = 10.*np.ones(units)\n",
    "    l_ang = 2.*np.ones(units)\n",
    "    kt = [('variance', v), \n",
    "          ('RBF', 'euclid', np.array([l, l, l_s])), \n",
    "          ('RBF', 'torus', np.array([l_ang, l_ang]))]\n",
    "    \n",
    "    covariates = (behav_tuple[0], behav_tuple[1], behav_tuple[2], behav_tuple[3], behav_tuple[4])\n",
    "    VI_tuples = [(None, None, None, 1)]*len(covariates)\n",
    "\n",
    "\n",
    "    inducing_points = np.array(ind_list).T[None, ...].repeat(units_, axis=0)\n",
    "    gp_rate = mdl.nonparametrics.Gaussian_process(units, inducing_points, kt, VI_tuples, \n",
    "                                                  inv_link='exp', shared_kernel_params=False,\n",
    "                                                  cov_type='factorized', mean=np.zeros((units)), \n",
    "                                                  whiten=True)\n",
    "    gp_rate.set_params(tbin, jitter=1e-5)\n",
    "    \n",
    "    return gp_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP with variable regressors model fit and nonconvexity\n",
    "nonconvex_trials = 3\n",
    "\n",
    "for trial in range(nonconvex_trials):\n",
    "    while True:\n",
    "        try:\n",
    "            glm_rate = GP_params(mode, behav_tuple, num_induc, maxspeed)\n",
    "\n",
    "            likelihood = mdl.likelihoods.Poisson(units, 'exp')\n",
    "            likelihood.set_params(tbin)\n",
    "\n",
    "            glm = mdl.inference.nll_optimized([glm_rate], renewal_dist)\n",
    "            glm.preprocess(list(covariates), covariates[0].shape[0], rc_t, batch_size=100000)\n",
    "            glm.to(dev)\n",
    "\n",
    "            # fit\n",
    "            sch = lambda o: optim.lr_scheduler.MultiplicativeLR(o, lambda e: 0.9)\n",
    "            opt_tuple = (optim.Adam, 100, sch)\n",
    "            opt_lr_dict = {'default': 5*1e-2}\n",
    "            glm.set_optimizers(opt_tuple, opt_lr_dict)\n",
    "\n",
    "            annealing = lambda x: 1.0#min(1.0, 0.002*x)\n",
    "            losses = glm.fit(3000, loss_margin=-1e1, stop_iters=100, anneal_func=annealing, \n",
    "                             cov_samples=1, ll_samples=10, ll_mode='MC', bound='ELBO')\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(losses)\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('NLL')\n",
    "            plt.show()\n",
    "\n",
    "            break\n",
    "        except (RuntimeError, AssertionError):\n",
    "            print('Retrying...')\n",
    "            if retries > 1: # max retries\n",
    "                print('Stopped.')\n",
    "                raise ValueError\n",
    "            retries += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place field\n",
    "grid_size = [int(arena_width/10), int(arena_height/10)]\n",
    "grid_shape = [[left_x, right_x], [bottom_y, top_y]]\n",
    "\n",
    "def func(pos):\n",
    "    prevshape = pos.shape[1:]\n",
    "    x = pos[0].flatten()\n",
    "    y = pos[1].flatten()\n",
    "    covariates = [x, y, SP*np.ones_like(x), \\\n",
    "                  TH*np.ones_like(x), HD*np.ones_like(x)]\n",
    "    return glm_rate.eval_rate(covariates, [0])[0].reshape(*prevshape)\n",
    "\n",
    "(xx, yy), place_field_ = tools.compute_mesh(grid_size, grid_shape, func)\n",
    "place_field.append(place_field_)\n",
    "    \n",
    "    \n",
    "# GP tuning\n",
    "steps= 100\n",
    "\n",
    "covariates = (X[n]*np.ones(steps), Y[n]*np.ones(steps), np.linspace(0, maxspeed, steps), \\\n",
    "              TH*np.ones(steps), HD*np.ones(steps))\n",
    "lower, mean, upper = glm_rate.eval_rate(covariates, [0], False)\n",
    "lower_s.append(lower[0])\n",
    "mean_s.append(mean[0])\n",
    "upper_s.append(upper[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
