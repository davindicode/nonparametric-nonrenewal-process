{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator # for minor ticks\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches\n",
    "from matplotlib.offsetbox import TextArea, VPacker, AnnotationBbox\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys, time\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from neuroprob import stats, tools, neural_utils\n",
    "import neuroprob.models as mdl\n",
    "\n",
    "dev = tools.PyTorch()\n",
    "\n",
    "import models\n",
    "\n",
    "plt.style.use(['paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place cells show overdispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcov, units_used, tbin, resamples, rc_t = binning(20, spktrain)\n",
    "\n",
    "show_neuron = [5, 13, 24]\n",
    "show_neurons = len(show_neuron)\n",
    "\n",
    "\n",
    "\n",
    "# computation\n",
    "ll_mode, r_mode, spk_cpl, num_induc = ('IP', 'hd', None, 8)\n",
    "glm, cov_used = models.set_glm(r_mode, ll_mode, spk_cpl, rcov, units_used, tbin, rc_t, num_induc, inv_link='exp')\n",
    "glm.to(dev)\n",
    "\n",
    "model_name = 'GPR_{}_{}'.format(session_id, r_mode)\n",
    "checkpoint = torch.load('./checkpoint/' + model_name)\n",
    "glm.load_state_dict(checkpoint['glm'])\n",
    "\n",
    "steps= 100\n",
    "covariates = np.linspace(0, 2*np.pi, steps)[None, :]\n",
    "\n",
    "lower, mean, upper = glm.rate_model[0].eval_rate(covariates, show_neuron, 'posterior')\n",
    "cnt_tuples_pl, _ = models.compute_count_stats(glm, 'IP', tbin, rc_t, cov_used, show_neuron, \n",
    "                                              traj_len=100, start=0, T=resamples, bs=10000)\n",
    "\n",
    "\n",
    "# large bin rates\n",
    "bsize = 1000\n",
    "bin_time, bin_samples, bc_t, (bhd_t,) = neural_utils.BinTrain(bsize, sample_bin, spktrain, \n",
    "                                                    spktrain.shape[1], (hd_t,), \n",
    "                                                    average_behav=False, binned=True)\n",
    "\n",
    "brate = bc_t[show_neuron, :]/bin_time\n",
    "\n",
    "\n",
    "\n",
    "rcov, units_used, tbin, resamples, rc_t = binning(1, spktrain)\n",
    "\n",
    "# computation\n",
    "ll_mode, r_mode, spk_cpl, num_induc = ('IP', 'hd', None, 8)\n",
    "rr_mode = r_mode + (spk_cpl if spk_cpl is not None else '')\n",
    "\n",
    "k = 0\n",
    "trunc = 250000\n",
    "trc_behav = [rc[k*trunc:(k+1)*trunc] for rc in rcov]\n",
    "Y = (rc_t[:, k*trunc:(k+1)*trunc] > 0) # correct for duplicate spikes\n",
    "glm, _ = models.set_glm(r_mode, ll_mode, spk_cpl, trc_behav, units_used, sample_bin, Y, num_induc, inv_link='exp', jitter=1e-4)\n",
    "glm.to(dev)\n",
    "\n",
    "model_name = 'GPPP_{}_{}_{}_{}'.format(session_id, ll_mode, rr_mode, k)\n",
    "checkpoint = torch.load('./checkpoint/' + model_name)\n",
    "glm.load_state_dict(checkpoint['glm'])\n",
    "\n",
    "isi_tuples_pl = models.compute_isi_stats(glm, ll_mode, tbin, rc_t, cov_used, show_neuron, start=0, T=trunc, bs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcov, units_used, tbin, resamples, rc_t = binning(20, spktrain)\n",
    "\n",
    "show_neuron = [9, 11, # PoS\n",
    "               15, 25] # ANT\n",
    "show_neurons = len(show_neuron)\n",
    "\n",
    "\n",
    "\n",
    "# computation\n",
    "ll_mode, r_mode, spk_cpl, num_induc = ('IP', 'hd_w', None, 16)\n",
    "glm, cov_used = models.set_glm(r_mode, ll_mode, spk_cpl, rcov, units_used, tbin, rc_t, num_induc, inv_link='exp')\n",
    "glm.to(dev)\n",
    "\n",
    "model_name = 'GPR_{}_{}'.format(session_id, r_mode)\n",
    "checkpoint = torch.load('./checkpoint/' + model_name)\n",
    "glm.load_state_dict(checkpoint['glm'])\n",
    "\n",
    "\n",
    "# compute preferred HD\n",
    "pref_hd = []\n",
    "ATI_N = 51\n",
    "w_arr = np.linspace(-5., 5., ATI_N)\n",
    "for w_eval in w_arr:\n",
    "    steps = 300\n",
    "    covariates = [np.linspace(0, 2*np.pi, steps+1)[:-1], \n",
    "                  w_eval*np.ones(steps)]\n",
    "    neurons = np.arange(units_used)\n",
    "    mean = glm.rate_model[0].eval_rate(covariates, neurons, 'mean')\n",
    "    Z = np.cos(covariates[0]) + np.sin(covariates[0])*1j # CoM angle\n",
    "    pref_hd.append(np.angle((Z[None, :]*mean).mean(-1)) % (2*np.pi))\n",
    "    #pref_hd.append(covariates[0][mean.argmax(-1)])\n",
    "pref_hd = np.array(pref_hd)\n",
    "\n",
    "# ATI\n",
    "ATI = []\n",
    "res_var = []\n",
    "for k in range(units_used):\n",
    "    _, a, shift, losses = tools.circ_lin_regression(pref_hd[:, k], w_arr/(2*np.pi), dev='cpu', iters=1000, lr=1e-2)\n",
    "    ATI.append(-a)\n",
    "    res_var.append(losses[-1])\n",
    "ATI = np.array(ATI)\n",
    "res_var = np.array(res_var)\n",
    "\n",
    "\n",
    "# tuning\n",
    "grid_size_hdw = (50, 40)\n",
    "grid_shape_hdw = [[0, 2*np.pi], [-20., 20.]]\n",
    "    \n",
    "def func(pos):\n",
    "    prevshape = pos.shape[1:]\n",
    "    x = pos[0].flatten()\n",
    "    y = pos[1].flatten()\n",
    "    covariates = np.array([x, y])\n",
    "    return glm.rate_model[0].eval_rate(covariates, show_neuron).reshape(show_neurons, *prevshape)\n",
    "\n",
    "_, field_hdw = tools.compute_mesh(grid_size_hdw, grid_shape_hdw, func)\n",
    "\n",
    "    \n",
    "    \n",
    "ll_mode, r_mode, spk_cpl, num_induc = ('IP', 'hd_w_s', None, 20)\n",
    "glm, cov_used = models.set_glm(r_mode, ll_mode, spk_cpl, rcov, units_used, tbin, rc_t, num_induc, inv_link='exp')\n",
    "glm.to(dev)\n",
    "\n",
    "model_name = 'GPR_{}_{}'.format(session_id, r_mode)\n",
    "checkpoint = torch.load('./checkpoint/' + model_name)\n",
    "glm.load_state_dict(checkpoint['glm'])\n",
    "    \n",
    "mean_s = []\n",
    "lower_s = []\n",
    "upper_s = []\n",
    "steps = 100\n",
    "covariates_s = np.linspace(0, 30., steps)\n",
    "for n in show_neuron:\n",
    "    covariates = [pref_hd[ATI_N//2, n]*np.ones(steps), # pref hd at zero AHV\n",
    "              np.zeros(steps),\n",
    "              covariates_s]\n",
    "    l, m, u = glm.rate_model[0].eval_rate(covariates, [n], 'posterior', n_samp=100000)\n",
    "    lower_s.append(l[0])\n",
    "    mean_s.append(m[0])\n",
    "    upper_s.append(u[0])\n",
    "    \n",
    "    \n",
    "ll_mode, r_mode, spk_cpl, num_induc = ('IP', 'hd_w_s_pos', None, 32)\n",
    "glm, cov_used = models.set_glm(r_mode, ll_mode, spk_cpl, rcov, units_used, tbin, rc_t, num_induc, inv_link='exp')\n",
    "glm.to(dev)\n",
    "\n",
    "model_name = 'GPR_{}_{}'.format(session_id, r_mode)\n",
    "checkpoint = torch.load('./checkpoint/' + model_name)\n",
    "glm.load_state_dict(checkpoint['glm'])\n",
    "\n",
    "grid_size_pos = (50, 40)\n",
    "grid_shape_pos = [[left_x, right_x], [bottom_y, top_y]]\n",
    "field_pos = []\n",
    "for n in show_neuron:\n",
    "    def func(pos):\n",
    "        prevshape = pos.shape[1:]\n",
    "        x = pos[0].flatten()\n",
    "        y = pos[1].flatten()\n",
    "        hd = pref_hd[ATI_N//2, n]*np.ones_like(x)\n",
    "        w = 0.*np.ones_like(x)\n",
    "        s = 0.*np.ones_like(x)\n",
    "        covariates = np.array([hd, w, s, x, y])\n",
    "        return glm.rate_model[0].eval_rate(covariates, n).reshape(*prevshape)\n",
    "\n",
    "    field_pos.append(tools.compute_mesh(grid_size_pos, grid_shape_pos, func)[1])\n",
    "field_pos = np.stack(field_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [('IP', 'hd', None, 8), \n",
    "         ('IP', 'hd_w', None, 16), \n",
    "         ('IP', 'hd_w_s', None, 20), \n",
    "         ('IP', 'hd_w_s_pos', None, 32)]\n",
    "\n",
    "\n",
    "\n",
    "T_DS_arr = []\n",
    "T_KS_arr = []\n",
    "p_DS_arr = []\n",
    "I_arr = []\n",
    "\n",
    "folds = 10\n",
    "cv_runs = np.arange(10)\n",
    "pred_LL_arr = []\n",
    "\n",
    "for m in modes:\n",
    "    ll_mode, r_mode, spk_cpl, num_induc = m\n",
    "    print(m)\n",
    "\n",
    "    T_DS_ = []\n",
    "    T_KS_ = []\n",
    "    p_DS_ = []\n",
    "    pred_LL_ = []\n",
    "\n",
    "    glm, cov_used = models.set_glm(r_mode, ll_mode, spk_cpl, rcov, units_used, tbin, rc_t, num_induc, inv_link='exp')\n",
    "    glm.to(dev)\n",
    "\n",
    "    model_name = 'GPR_{}_{}'.format(session_id, r_mode)\n",
    "    checkpoint = torch.load('./checkpoint/' + model_name)\n",
    "    glm.load_state_dict(checkpoint['glm'])\n",
    "    \n",
    "    cv_set = neural_utils.SpikeTrainCV(folds, rc_t, rc_t.shape[1], rcov)\n",
    "    for kcv in cv_runs:\n",
    "        ftrain, fcov, vtrain, vcov = cv_set[kcv]\n",
    "        vcov_used = models.cov_used(r_mode, vcov)\n",
    "        pred_LL_.append(models.pred_ll(glm, vtrain, vcov_used, vtrain.shape[-1], np.arange(units_used)))\n",
    "\n",
    "    cnt_tuples, I = models.compute_count_stats(glm, 'IP', tbin, rc_t, cov_used, np.arange(units_used), 100, \n",
    "                                               start=0, T=resamples, bs=5000)\n",
    "    for cnt_tuple in cnt_tuples:\n",
    "        q_cdf, Z_DS, T_KS, s_DS, s_KS, p_DS, p_KS = cnt_tuple\n",
    "        T_DS_.append(Z_DS)\n",
    "        T_KS_.append(T_KS)\n",
    "        p_DS_.append(p_DS)\n",
    "        \n",
    "    T_DS_arr.append(T_DS_)\n",
    "    T_KS_arr.append(T_KS_)\n",
    "    p_DS_arr.append(p_DS_)\n",
    "    I_arr.append(I)\n",
    "    pred_LL_arr.append(pred_LL_)\n",
    "    \n",
    "T_DS_arr = np.array(T_DS_arr)\n",
    "T_KS_arr = np.array(T_KS_arr)\n",
    "p_DS_arr = np.array(p_DS_arr)\n",
    "I_arr = np.array(I_arr)\n",
    "pred_LL_arr = np.array(pred_LL_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = [50, 40]\n",
    "grid_shape = [[left_x, right_x], [bottom_y, top_y]]\n",
    "N_x = 6\n",
    "N_y = 6\n",
    "neurons = units_used#N_x*N_y\n",
    "\n",
    "def func(pos):\n",
    "    prevshape = pos.shape[1:]\n",
    "    x = pos[0].flatten()\n",
    "    y = pos[1].flatten()\n",
    "    theta = np.zeros_like(x)\n",
    "    covariates = [x, y, theta]\n",
    "    return gp_lvm.eval_rate(covariates, np.arange(neurons)).reshape(neurons, *prevshape)\n",
    "\n",
    "(xx, yy), place_field = tools.compute_mesh(grid_size, grid_shape, func)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((cnt_tuples_pl, isi_tuples_pl, covariates, lower, mean, upper, brate, bhd_t, \\\n",
    "             T_DS_arrl, T_KS_arrl, traj_arr, T_DS_arrs, T_KS_arrs, I_arrs, pred_LL, \\\n",
    "             show_neuron, tbin, shift_times), open('./output/ca1.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
