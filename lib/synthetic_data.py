from functools import partial
import jax
import jax.numpy as jnp

import jax
from jax import vmap, jit, grad, ops, lax, config
import jax.random as jr


import numpy as np








def requad(x):
    return 0.5*(x + jnp.sqrt(x*x+4))-1



def pendulum_LDS(omega=1. , decay=0.):
    F = jnp.asarray([[-decay, 1], [-omega**2, -decay]])
    return F





def generate_from_LDS(key, n_latents, timesteps, process_noise_var=0.1, x0 = None, 
                      F = None, L = None, n_trials = 1):
    """
    if F is none, generate a random stable LDS (from LEG parametrization, 
    not the most minimal but should be fine here)
    
    key -> random number to generate random trajectories
    n_latents -> size of latent state
    n_output -> size of output (observation mapping is a separate fuction)
    timesteps -> time points at which we evaluate the LDS/if not in order we reorder 
    :param np.array L: noise matrix
    :param float process_noise_var: variance of the process noise
    :param np.array F: if we want to pass in the LDS we are modelling
    :param int n_trials: if we want to generate outputs of multiple trials 
    :return:
        returns n_trials trajectories generated by the LDS, with different process noise for each
    """
    key, subkey = jr.split(key)
    if F is None : 
        key, subkey = jr.split(key)
        
        N = jr.normal(key, shape=(n_latents, n_latents))
        R = jr.normal(subkey, shape=(n_latents, n_latents))
        G = N@N.T + R - R.T
        L = jnp.eye(n_latents)
        F = -G/2
        
    if x0 is None : 
        x0 = jr.normal(subkey,(n_trials, n_latents, 1))
        
    dts = timesteps[1:] - timesteps[:-1]
    _, subkey = jr.split(subkey)
    n_steps = jnp.shape(dts)[0]
    process_noise = jr.normal(subkey, (n_trials, n_steps, n_latents, 1))
    Qc = jnp.sqrt(process_noise_var)
    
    def unroll_traj(x0, eps_traj):
        def dyn(x, inpts):
            dt, eps = inpts
            x_next = x + dt * F @ x + Qc*jnp.sqrt(dt) * L @ eps
            #print(x.shape, x_next.shape, eps.shape)
            return x_next, x_next
        inpts = dts, eps_traj
        return jax.lax.scan(dyn, x0, inpts)
    
    _, X = jax.vmap(unroll_traj, in_axes =(0,0))(x0, process_noise) 
    return X[..., 0]
    
    

def add_poisson_noise(key, rates, timesteps, n_output=None, mean_bias = 5.):
    """Takes a trajectory, and maps it onto an output space of spiking neurons
    Inputs : latent_trajs are the latent trajectories which we are mapping onto the output space #size n_trials x n_steps x n_latents
    timesteps are the time indices for each observation 
    n_output is the number of output dimensions (by default it's going to be equal to n_latents)"""
    n_latents = jnp.shape(latent_trajs)[-2]
    print(n_latents)
    key, subkey = jr.split(key)
    if n_output is None : 
        C = jnp.eye(n_latents)
    else :
        C = jr.normal(key,(n_output, n_latents))
    bias = jr.uniform(subkey,(n_output, 1),minval = 0.0, maxval=2*mean_bias)
    _, subsubkey = jr.split(subkey)
    output_trajs = jax.vmap(jnp.matmul, in_axes = (None,1), out_axes = 1)(C, latent_trajs) + bias
    print(output_trajs.shape)
    rates = jax.nn.relu(output_trajs)
    print(timesteps.shape,"shape time")
    dts = timesteps[1:] - timesteps[:-1]
    mus = rates*dts[None,:,None,None]
    return jax.random.poisson(subsubkey, lam=mus)



def add_gaussian_noise(key, latent_trajs, sigma_obs=0.1, n_output=None, return_pre=False):
    """Takes a trajectory, and maps it onto an output space of spiking neurons
    Inputs : latent_trajs are the latent trajectories which we are mapping onto the output space #size n_trials x n_steps x n_latents
    timesteps are the time indices for each observation 
    n_output is the number of output dimensions (by default it's going to be equal to n_latents)"""
    n_latents = jnp.shape(latent_trajs)[-2]
    if n_output is None : 
        C = jnp.eye(n_latents)
    else :
        C = jr.normal(key,(n_output, n_latents))
    print(latent_trajs.shape, C.shape)
    output_trajs = jax.vmap(jnp.matmul, in_axes = (None,1), out_axes = 1)(C, latent_trajs)
    shp_traj = jnp.shape(output_trajs)
    if return_pre:
        return output_trajs + sigma_obs*jr.normal(key, shp_traj), output_trajs
    else :
        return output_trajs + sigma_obs*jr.normal(key, shp_traj)


def lorenz_trajs(key, timesteps, n_trials=1, sigma = 10., rho=28, beta=8/3):
    dts = timesteps[1:] - timesteps[:-1]
    x0s = 10*jr.normal(key,(n_trials, 3, 1))
    @jit
    def f(state):
        x, y, z = state[0], state[1], state[2]
        return jnp.array([sigma * (y - x), x * (rho - z) - y, x * y - beta * z])
    def unroll_dyn(x0):
        def dyn(x, inpts):
            dt = inpts
            print(dt)
            k1 = dt * f(x)
            k2 = dt * f(x + k1/2.)
            k3 = dt * f(x + k2/2.)
            k4 = dt * f(x + k3)
            x_next = x + 1./6 * (k1 + 2 * k2 + 2 * k3 + k4)
            return x_next, x_next
        inpts = dts
        return jax.lax.scan(dyn, x0, inpts)
    _, X = jax.vmap(unroll_dyn)(x0s)
    return X


def duffing_trajs(key, timesteps, n_trials=1):
    dts = timesteps[1:] - timesteps[:-1]
    x0s = jr.normal(key,(n_trials, 2, 1))
    @jit
    def f(state):
        x, y = state[0], state[1]
        return jnp.array([y, x - x*x*x])
    def unroll_dyn(x0):
        def dyn(x, inpts):
            dt = inpts
            k1 = dt * f(x)
            k2 = dt * f(x + k1/2.)
            k3 = dt * f(x + k2/2.)
            k4 = dt * f(x + k3)
            x_next = x + 1./6 * (k1 + 2 * k2 + 2 * k3 + k4)
            return x_next, x_next
        inpts = dts
        return jax.lax.scan(dyn, x0, inpts)
    _,X = jax.vmap(unroll_dyn)(x0s)
    return X




### neural populations ###
def GLM(x, w, nonlin=jnp.exp):
    """
    :param np.array x: input of shape (trials, time, in_dims)
    :param np.array C: loading matrix (out_dims, in_dims)
    :param np.array b: bias (out_dims)
    :return:
        rate of shape (trials, time, out_dims)
    """
    g = jnp.concatenate((x, jnp.ones_like(x[..., :1])), axis=2)
    return nonlin((g[..., None, :]*w[None, None, ...]).sum(-1))



def vonMises_GLM(x, w, nonlin=jnp.exp):
    """
    Angular (head direction/theta) variable GLM
    
    :param np.array x: input head direction series of shape (trials, time, 1)
    :param np.array w: weights of shape (neurons, 3,)
    :return:
        rate array of shape (trials, time, neurons)
    """
    s = jnp.sin(x)
    c = jnp.cos(x)
    g = jnp.concatenate((c, s, jnp.ones_like(x)), axis=2)
    return nonlin((g[..., None, :]*w[None, None, ...]).sum(-1))



def quadratic_GLM(x, w, nonlin=jnp.exp):
    """
    Quadratic GLM for position
    
    :param np.array x: input series of shape (trials, time, 2)
    :param np.array w: weights of shape (neurons, 6)
    :return:
        rate array of shape (trials, time, neurons)
    """
    x, y = x[..., 0], x[..., 1]
    g = jnp.stack((jnp.ones_like(x), x, y, x**2, y**2, x*y), axis=-1)
    return nonlin((g[..., None, :]*w[None, None, ...]).sum(-1))
    
    
    

def HDC_bumps(hd_t, neurons, key=jr.PRNGKey(123)):
    """
    :param np.array hd_t: input series of shape (trials, time)
    :return:
        rate array of shape (trials, time, neurons)
    """
    keys = jr.split(key, 3)
    p_c = jr.normal(keys[0], shape=(neurons,))**2 + 1.0
    p_a = jnp.maximum(0.0, 30.0 + 0.1*jr.normal(keys[1], shape=(neurons,)))
    p_b = 0.2*jr.normal(keys[2], shape=(neurons,))**2 + 0.3
    p_z = jnp.linspace(0, 2*jnp.pi, neurons+1)[:-1]

    rates = p_c[None, None, :] + p_a[None, None, :]*jnp.exp(
        (jnp.cos(hd_t[..., None] - p_z[None, None, :])-1)/p_b[None, None, :])
    return rates
    
    
    
def grid_cells(x, theta, phase, lamb, a=0.3):
    """
    Grid cells activity maps as presented in:
    - Blair et al. (2007), equation (1)
    - Almeida et al. (2009), equation (1)
    Incorporates theta modulation

    theta (float)             : Grid rotation (assume to be either 0°, 20°, or 40°, in degrees)
    phase (tuple of int)      : Spatial phase of the grid     
    lamb (int)                : Distance between firing fields

    :param np.array x: shape (trials, time, 2)
    :param np.array theta: shape (neurons,)
    :param np.array phase: shape (neurons, 2)
    :param np.array lamb: shape (neurons,)
    :param np.array x: covariates with shape (samples, timesteps, dims), [x, y]
    :return:
        rates with shape (trials, time, neurons)
    """
    b = 3./2.
    lambV = (4*jnp.pi)/(jnp.sqrt(3*lamb))[None, None, :]
    
    tmp_g = 0
    for i in jnp.deg2rad(jnp.linspace(-30, 90, 3)):
        u_f = jnp.stack((jnp.cos(i+theta), jnp.sin(i+theta)), axis=-1)[None, None, ...]
        dist = x[..., None, :] - phase[None, None, ...]
        tmp_g += jnp.cos(lambV * (u_f*dist).sum(-1))

    h = jnp.exp(a*(tmp_g+b))-1
    return h


# parameterizations
def w_to_gaussian(w):
    """
    Get Gaussian and orthogonal theta parameterization from the GLM parameters.
    
    :param np.array w: input GLM parameters of shape (neurons, dims), dims labelling (w_1, w_x,
                       w_y, w_xx, w_yy, w_xy, w_cos, w_sin)
    """
    neurons = mu.shape[0]
    w_spat = w[:, 0:6]
    prec = np.empty((neurons, 3)) # xx, yy and xy/yx
    mu = np.empty((neurons, 2)) # x and y
    prec[:, 0] = -2*w_spat[:, 3]
    prec[:, 1] = -2*w_spat[:, 4]
    prec[:, 2] = -w_spat[:, 5]
    prec_mat = []
    for n in range(neurons):
        prec_mat.append([[prec[n, 0], prec[n, 2]], [prec[n, 2], prec[n, 1]]])
    prec_mat = np.array(prec_mat)
    denom = prec[:, 0]*prec[:, 1] - prec[:, 2]**2
    mu[:, 0] = (w_spat[:, 1]*prec[:, 1] - w_spat[:, 2]*prec[:, 2])/denom
    mu[:, 1] = (w_spat[:, 2]*prec[:, 0] - w_spat[:, 1]*prec[:, 2])/denom
    rate_0 = np.exp(w_spat[:, 0] + 0.5*(mu * np.einsum('nij,nj->ni', prec_mat, mu)).sum(1))

    w_theta = w[:, 6:]
    theta_0 = np.angle(w_theta[:, 0] + w_theta[:, 1]*1j)
    beta = np.sqrt(w_theta[:, 0]**2 + w_theta[:, 1]**2)

    return mu, prec, rate_0, np.concatenate((beta[:, None], theta_0[:, None]), axis=1)


def gaussian_to_w(mu, prec, rate_0, theta_p):
    """
    Get GLM parameters from Gaussian and orthogonal theta parameterization
    
    :param np.array mu: mean of the Gaussian field of shape (neurons, 2)
    :param np.array prec: precision matrix elements xx, yy, and xy of shape (neurons, 3)
    :param np.array rate_0: rate amplitude of shape (neurons)
    :param np.array theta_p: theta modulation parameters beta and theta_0 of shape (neurons, 2)
    """
    neurons = mu.shape[0]
    prec_mat = []
    for n in range(neurons):
        prec_mat.append([[prec[n, 0], prec[n, 2]], [prec[n, 2], prec[n, 1]]])
    prec_mat = np.array(prec_mat)
    w = np.empty((neurons, 8))
    w[:, 0] = np.log(rate_0) - 0.5*(mu * np.einsum('nij,nj->ni', prec_mat, mu)).sum(1)
    w[:, 1] = mu[:, 0]*prec[:, 0] + mu[:, 1]*prec[:, 2]
    w[:, 2] = mu[:, 1]*prec[:, 1] + mu[:, 0]*prec[:, 2]
    w[:, 3] = -0.5*prec[:, 0]
    w[:, 4] = -0.5*prec[:, 1]
    w[:, 5] = -prec[:, 2]
    w[:, 6] = theta_p[:, 0]*np.cos(theta_p[:, 1])
    w[:, 7] = theta_p[:, 0]*np.sin(theta_p[:, 1])
    return w


def w_to_vonmises(w):
    """
    :param np.array w: parameters of the GLM of shape (neurons, 3)
    """
    rate_0 = w[:, 0]
    theta_0 = np.angle(w[:, 1] + w[:, 2]*1j)
    kappa = np.sqrt(w[:, 1]**2 + w[:, 2]**2)
    return rate_0, kappa, theta_0


def vonmises_to_w(rate_0, kappa, theta_0):
    """
    :param np.array rate_0: rate amplitude of shape (neurons)
    :param np.array theta_p: von Mises parameters kappa and theta_0 of shape (neurons, 2) 
    """
    neurons = rate_0.shape[0]
    w = np.empty((neurons, 3))
    w[:, 0] = np.log(rate_0)
    w[:, 1] = kappa*np.cos(theta_0)
    w[:, 2] = kappa*np.sin(theta_0)
    return w